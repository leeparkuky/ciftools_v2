{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea0d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ca_file_path = 'appalachian_counties2.csv'\n",
    "ca = pd.read_csv(ca_file_path, dtype={'FIPS':str})\n",
    "state_FIPS = ca.FIPS.apply(lambda x: x[:2]).unique().tolist()\n",
    "if len(state_FIPS) == 1:\n",
    "    state_fips = state_FIPS[0]\n",
    "else:\n",
    "    state_fips = state_FIPS\n",
    "    \n",
    "    \n",
    "    \n",
    "from utils import stateDf\n",
    "if isinstance(state_fips, str):\n",
    "    location = stateDf.loc[stateDf.FIPS2.eq(state_fips), 'StateAbbrev'].values[0]\n",
    "else:\n",
    "    location = stateDf.loc[stateDf.FIPS2.isin(state_fips), 'StateAbbrev'].values.tolist()\n",
    "\n",
    "from CIFTools import lung_cancer_screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31178741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on LCSR data...\n",
      "LCSR data ready\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xj/07knx1_11gl5w1nv4tg4xr000000gn/T/ipykernel_54546/3154773612.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlung_cancer_screening\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Lee/ciftools_v2/CIFTools.py\u001b[0m in \u001b[0;36mlung_cancer_screening\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0mdownloads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ACRLCSDownload*.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_lcs_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0mchrome_driver_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_chrome_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = lung_cancer_screening(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "    state = driver.find_elements(By.CLASS_NAME, 'tabComboBoxButtonHolder')[2]; state.click(); time.sleep(10)\n",
    "    state2 = driver.find_elements(By.CLASS_NAME, 'tabMenuItemNameArea')[1]; state2.click(); time.sleep(10)\n",
    "    download = driver.find_element(By.ID, 'tabZoneId422'); download.click()\n",
    "    x = num_downloads\n",
    "    t = 0\n",
    "    while t < x:\n",
    "        time.sleep(5)\n",
    "        t = len(glob('./ACRLCSDownload*.csv'))\n",
    "        print('Waiting on LCSR data...')\n",
    "    else:\n",
    "        print('LCSR data ready')\n",
    "    driver.close()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ea6de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL data is not available\n"
     ]
    }
   ],
   "source": [
    "df = superfund(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b83db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa3ba73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42    125\n",
       "36    119\n",
       "39     44\n",
       "37     42\n",
       "51     35\n",
       "45     32\n",
       "24     24\n",
       "47     24\n",
       "13     21\n",
       "21     20\n",
       "28     13\n",
       "54     13\n",
       "na      5\n",
       "Name: FIPS5, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.FIPS5.apply(lambda x: str(x)[:2]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e38be9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "count = 60000\n",
    "taxonomy = 'obstetrics'\n",
    "location = 'NY'\n",
    "url = f'https://npiregistry.cms.hhs.gov/api/?version=2.1&address_purpose=LOCATION&number=&state={location}&taxonomy_description={taxonomy}&skip={200*(count -1)}&limit=200'\n",
    "resp = requests.get(url)\n",
    "output = resp.json()\n",
    "result_count = output['result_count']\n",
    "df = pd.DataFrame(output['results'])\n",
    "df['Name'] = df.basic.apply(parse_basic)\n",
    "df['Phone_number'] = df.addresses.apply(lambda x: parse_address(x)[1])\n",
    "df['Address'] = df.addresses.apply(lambda x: parse_address(x)[0])\n",
    "if taxonomy in taxonomy_names.keys():\n",
    "    df['Type']    = taxonomy_names[taxonomy]\n",
    "else:\n",
    "    df['Type']    = taxonomy\n",
    "df['Notes']   = ''\n",
    "if result_count == 200:\n",
    "    datasets.append(df[['Type','Name','Address','Phone_number', 'Notes']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c8e2603",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 60200\n",
    "taxonomy = 'obstetrics'\n",
    "location = 'NY'\n",
    "url = f'https://npiregistry.cms.hhs.gov/api/?version=2.1&address_purpose=LOCATION&number=&state={location}&taxonomy_description={taxonomy}&skip={200*(count -1)}&limit=200'\n",
    "resp = requests.get(url)\n",
    "output = resp.json()\n",
    "result_count = output['result_count']\n",
    "df = pd.DataFrame(output['results'])\n",
    "df['Name'] = df.basic.apply(parse_basic)\n",
    "df['Phone_number'] = df.addresses.apply(lambda x: parse_address(x)[1])\n",
    "df['Address'] = df.addresses.apply(lambda x: parse_address(x)[0])\n",
    "if taxonomy in taxonomy_names.keys():\n",
    "    df['Type']    = taxonomy_names[taxonomy]\n",
    "else:\n",
    "    df['Type']    = taxonomy\n",
    "df['Notes']   = ''\n",
    "if result_count == 200:\n",
    "    datasets.append(df[['Type','Name','Address','Phone_number', 'Notes']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dce00835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "31//30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b8b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Union, List\n",
    "import requests\n",
    "import urllib\n",
    "import asyncio\n",
    "import re\n",
    "import functools\n",
    "from functools import partial\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from glob import glob\n",
    "from typing import Union, List\n",
    "from os import getcwd, remove\n",
    "from csv import DictReader\n",
    "from itertools import product\n",
    "# for ascync requests\n",
    "from aiohttp import ClientSession\n",
    "# cfg\n",
    "from CIF_Config import ACSConfig, SocrataConfig\n",
    "# pandas / numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# multi-processing\n",
    "from joblib import Parallel, delayed\n",
    "# import stateDF from utils\n",
    "from utils import stateDf\n",
    "# import beautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "def parse_basic(basic):\n",
    "    if 'organization_name' in basic.keys():\n",
    "        name = basic['organization_name'].title()\n",
    "    else:\n",
    "        if 'middle_name' in basic.keys():\n",
    "            name = basic['first_name'].title() + ' ' + basic['middle_name'][0].upper() + ' ' + basic['last_name'].title()\n",
    "        else:\n",
    "            name = basic['first_name'].title() + ' ' + basic['last_name'].title()\n",
    "        if 'credential' in basic.keys():\n",
    "            name = name + ' ' + basic['credential'].upper()\n",
    "    return name\n",
    "\n",
    "\n",
    "def parse_address(address):\n",
    "    address_dict = [x for x in address if x['address_purpose'] == 'LOCATION'][0]\n",
    "    if 'address_2' in address_dict.keys():\n",
    "        street = address_dict['address_1'].title() + ', ' + address_dict['address_2'].title() + ', ' + address_dict['city'].title() + ', ' + address_dict['state'].upper() + ' ' + address_dict['postal_code'][:5]\n",
    "    else:\n",
    "        street = address_dict['address_1'].title() + ', ' + address_dict['city'].title() + ', ' + address_dict['state'].upper() + ' ' + address_dict['postal_code'][:5]\n",
    "    if 'telephone_number' in address_dict.keys():\n",
    "        phone_number = address_dict['telephone_number']\n",
    "    else:\n",
    "        phone_number = None\n",
    "    return street, phone_number\n",
    "\n",
    "\n",
    "taxonomy = ['Gastroenterology','colon','obstetrics']\n",
    "\n",
    "taxonomy_names = dict(zip(taxonomy, ['Gastroenterology','Colon & Rectal Surgeon','Obstetrics & Gynecology']))\n",
    "\n",
    "def gen_nppes_by_taxonomy(taxonomy: str, location: str):\n",
    "    count = 0\n",
    "    result_count = 200\n",
    "    skip = 0\n",
    "    datasets = []\n",
    "    while result_count == 200:\n",
    "        count += 1\n",
    "        print(count)\n",
    "        url = f'https://npiregistry.cms.hhs.gov/api/?version=2.1&address_purpose=LOCATION&number=&state={location}&taxonomy_description={taxonomy}&skip={200*(count -1)}&limit=200'\n",
    "        resp = requests.get(url)\n",
    "        output = resp.json()\n",
    "        result_count = output['result_count']\n",
    "        df = pd.DataFrame(output['results'])\n",
    "        df['Name'] = df.basic.apply(parse_basic)\n",
    "        df['Phone_number'] = df.addresses.apply(lambda x: parse_address(x)[1])\n",
    "        df['Address'] = df.addresses.apply(lambda x: parse_address(x)[0])\n",
    "        if taxonomy in taxonomy_names.keys():\n",
    "            df['Type']    = taxonomy_names[taxonomy]\n",
    "        else:\n",
    "            df['Type']    = taxonomy\n",
    "        df['Notes']   = ''\n",
    "        if result_count == 200:\n",
    "            datasets.append(df[['Type','Name','Address','Phone_number', 'Notes']])\n",
    "        elif count == 1:\n",
    "            return df[['Type','Name','Address','Phone_number', 'Notes']]\n",
    "        else:\n",
    "            datasets.append(df[['Type','Name','Address','Phone_number', 'Notes']])\n",
    "            result = pd.concat(datasets, axis = 0).reset_index(drop = True)\n",
    "            return result\n",
    "        \n",
    "def nppes(location:Union[str, List[str]], taxonomy:List[str] = ['Gastroenterology','colon','obstetrics']) -> pd.DataFrame:\n",
    "    if isinstance(location, str):\n",
    "        res = Parallel(n_jobs=-1)(delayed(gen_nppes_by_taxonomy)(t, location) for t in taxonomy)\n",
    "    else:\n",
    "        from itertools import product\n",
    "        res = Parallel(n_jobs=-1)(delayed(gen_nppes_by_taxonomy)(t, loc) for t, loc in product(taxonomy, location))\n",
    "    return pd.concat(res, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27fcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
