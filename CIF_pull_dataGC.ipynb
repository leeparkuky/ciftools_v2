{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-m-IXs4afdm4"
   },
   "source": [
    "# CIFTools Google Colab Runtime\n",
    "\n",
    "The following will allow you to pull data from several Federal data sources and filter them to your catchment area or other geographic area of interest.\n",
    "\n",
    "To begin, you will need to install or upgrade some modules on your Google Colab runtime. This only needs to be done the first time you run this on each visit. \n",
    "\n",
    "*After successful completion you may want to clear the terminal to reduce clutter*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER88kcaef3Ef"
   },
   "source": [
    "Next, you will need to upload the `CIFTools-main.zip`.    \n",
    "\n",
    "Then executing `unzip`, all the files for the CIFTools will be set-up and ready-to-use in the `CIFTools-main` folder.    \n",
    "Within the `CIFTools-main`, there are not only the `CIFTools.py` module and all the catchment area csv files within the `catment_area` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7W8q5EnaEyI"
   },
   "outputs": [],
   "source": [
    "### upload CIFToolsGC.py and your catchment area file\n",
    "\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will change the working directory for both terminal and python kernel within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip CIFTools-main.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(os.getcwd(), 'CIFTools-main'))\n",
    "%pip install -r requirements.txt\n",
    "from utils import write_bash_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import write_bash_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "?write_bash_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "ca_file_path = os.path.join(os.getcwd(), glob('*/uky_ca.csv')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_bash_script('markey', ca_file_path ,['county','tract'], 2019, ['pickle','csv','excel'], 'f1a4c4de1f35fe90fc1ceb60fd97b39c9a96e436')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEW_y8GIb_yR"
   },
   "outputs": [],
   "source": [
    "### main file to pull and wrangle catchment area data\n",
    "\"\"\"\n",
    "Created on Tue May 31 02:12:09 2022\n",
    "\n",
    "@author: Todd Burus and Lee Park, University of Kentucky, Markey Cancer Center\n",
    "\n",
    "Copyright 2022, University of Kentucky\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from io import StringIO\n",
    "from CIFToolsGC import census_sdoh as sdoh\n",
    "from CIFToolsGC import BLS\n",
    "from CIFToolsGC import food_desert\n",
    "from CIFToolsGC import fcc\n",
    "from CIFToolsGC import facilities \n",
    "from CIFToolsGC import water_violation\n",
    "from CIFToolsGC import scp_cancer_data\n",
    "from CIFToolsGC import places_data\n",
    "\n",
    "#################################################\n",
    "### customize paths and files before running  ###\n",
    "#################################################\n",
    "if __name__ == '__main__':\n",
    "    ### input default download path for Chrome (/content for Google Colab)\n",
    "    dl_path = '/content'\n",
    "    \n",
    "    ### input file name for catchment area county list\n",
    "    ca_file = input(r'What file contains your catchment area counties?: ') #'uky_ca.csv'\n",
    "    \n",
    "    ### input name of catchment area\n",
    "    ca_name = input(r'Give a short name to identify your cancer center in save files: ') #Markey\n",
    "\n",
    "#################################################\n",
    "\n",
    "### create table and dataframe of states\n",
    "state = '''State,FIPS2,StateAbbrev\n",
    "Alabama,01,AL\n",
    "Alaska,02,AK\n",
    "Arizona,04,AZ\n",
    "Arkansas,05,AR\n",
    "California,06,CA\n",
    "Colorado,08,CO\n",
    "Connecticut,09,CT\n",
    "Delaware,10,DE\n",
    "District of Columbia,11,DC\n",
    "Florida,12,FL\n",
    "Georgia,13,GA\n",
    "Hawaii,15,HI\n",
    "Idaho,16,ID\n",
    "Illinois,17,IL\n",
    "Indiana,18,IN\n",
    "Iowa,19,IA\n",
    "Kansas,20,KS\n",
    "Kentucky,21,KY\n",
    "Louisiana,22,LA\n",
    "Maine,23,ME\n",
    "Maryland,24,MD\n",
    "Massachusetts,25,MA\n",
    "Michigan,26,MI\n",
    "Minnesota,27,MN\n",
    "Mississippi,28,MS\n",
    "Missouri,29,MO\n",
    "Montana,30,MT\n",
    "Nebraska,31,NE\n",
    "Nevada,32,NV\n",
    "New Hampshire,33,NH\n",
    "New Jersey,34,NJ\n",
    "New Mexico,35,NM\n",
    "New York,36,NY\n",
    "North Carolina,37,NC\n",
    "North Dakota,38,ND\n",
    "Ohio,39,OH\n",
    "Oklahoma,40,OK\n",
    "Oregon,41,OR\n",
    "Pennsylvania,42,PA\n",
    "Rhode Island,44,RI\n",
    "South Carolina,45,SC\n",
    "South Dakota,46,SD\n",
    "Tennessee,47,TN\n",
    "Texas,48,TX\n",
    "Utah,49,UT\n",
    "Vermont,50,VT\n",
    "Virginia,51,VA\n",
    "Washington,53,WA\n",
    "West Virginia,54,WV\n",
    "Wisconsin,55,WI\n",
    "Wyoming,56,WY\n",
    "'''\n",
    "\n",
    "dfCsv = StringIO(state)\n",
    "\n",
    "stateDf = pd.read_csv(dfCsv, sep=',', dtype={'State':str, 'FIPS2':str, 'StateAbbrev':str})\n",
    "\n",
    "### subset for catchment area\n",
    "ca = pd.read_csv(ca_file, dtype={'FIPS':str})\n",
    "ca = pd.merge(ca, stateDf, on='State', how='left')\n",
    "caState = ca.State.unique().tolist()\n",
    "caSA = ca.StateAbbrev.unique().tolist()\n",
    "caFIPS = ca.FIPS.unique().tolist()\n",
    "caStateFIPS = ca.FIPS2.unique().tolist()\n",
    "\n",
    "### run county sdoh function for catchment area or all US counties\n",
    "sdoh_county_df = dict()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        for s in caStateFIPS:\n",
    "            print(f'Collecting county-level Census data for {s}')\n",
    "            sdoh_county = sdoh(region = 'County', state=s, run_query = True, year = 2021)\n",
    "            if len(sdoh_county_df) == 0:\n",
    "                sdoh_county_df = sdoh_county.sdoh_df\n",
    "            else:\n",
    "                for k, v in sdoh_county.sdoh_df.items():\n",
    "                    sdoh_county_df[k] = pd.concat([sdoh_county_df[k], \n",
    "                                                   sdoh_county.sdoh_df[k]])\n",
    "            del sdoh_county\n",
    "            for k, v in sdoh_county_df.items():\n",
    "                sdoh_county_df[k] = sdoh_county_df[k][sdoh_county_df[k]['FIPS'].isin(caFIPS)]\n",
    "    except NameError:\n",
    "        for s in stateDf.FIPS2:\n",
    "            sdoh_county = sdoh(region = 'County', state=s, run_query = True, year = 2021)\n",
    "            if len(sdoh_county_df) == 0:\n",
    "                sdoh_county_df = sdoh_county.sdoh_df\n",
    "            else:\n",
    "                for k, v in sdoh_county.sdoh_df.items():\n",
    "                    sdoh_county_df[k] = pd.concat([sdoh_county_df[k], sdoh_county.sdoh_df[k]])\n",
    "            del sdoh_county\n",
    "\n",
    "\n",
    "### run tract sdoh function for catchment area or all US Census tracts\n",
    "sdoh_tract_df = dict()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        for s in caStateFIPS:\n",
    "            print(f'Collecting Census tract-level Census data for {s}')\n",
    "            sdoh_tract = sdoh(region = 'Tract', state=s, run_query = True, year = 2021)\n",
    "            if len(sdoh_tract_df) == 0:\n",
    "                sdoh_tract_df = sdoh_tract.sdoh_df\n",
    "            else:\n",
    "                for k, v in sdoh_tract.sdoh_df.items():\n",
    "                    sdoh_tract_df[k] = pd.concat([sdoh_tract_df[k], sdoh_tract.sdoh_df[k]])\n",
    "            del sdoh_tract\n",
    "            for k, v in sdoh_tract_df.items():\n",
    "                sdoh_tract_df[k]['FIPS5'] = sdoh_tract_df[k]['FIPS'].str[0:5]\n",
    "                sdoh_tract_df[k] = sdoh_tract_df[k][sdoh_tract_df[k]['FIPS5'].isin(caFIPS)]\n",
    "                sdoh_tract_df[k] = sdoh_tract_df[k].drop(columns=['FIPS5'])\n",
    "    except NameError:\n",
    "        for s in stateDf.FIPS2:\n",
    "            sdoh_tract = sdoh(region = 'Tract', state=s, run_query = True, year = 2021)\n",
    "            if len(sdoh_tract_df) == 0:\n",
    "                sdoh_tract_df = sdoh_tract.sdoh_df\n",
    "            else:\n",
    "                for k, v in sdoh_tract.sdoh_df.items():\n",
    "                    sdoh_tract_df[k] = pd.concat([sdoh_tract_df[k], sdoh_tract.sdoh_df[k]])\n",
    "            del sdoh_tract\n",
    "\n",
    "\n",
    "### run county monthly unemployment for catchment area of all US counties\n",
    "bls_df = pd.DataFrame()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        for s in caStateFIPS:\n",
    "            print(f'Collecting county-level labor statistics for {s}')\n",
    "            bls = BLS(state = s)\n",
    "            bls.df[f'Monthly Unemployment Rate ({bls.df.Period.unique()[0]})'] = bls.df['Unemployment Rate']*0.01\n",
    "            bls.df = bls.df.drop(columns=['Unemployment Rate', 'Period'])\n",
    "            bls.df = bls.df[bls.df['FIPS'].isin(caFIPS)]\n",
    "            bls_df = pd.concat([bls_df, bls.df], ignore_index=True)\n",
    "            del bls\n",
    "    except NameError:\n",
    "        for s in stateDf.FIPS2:\n",
    "            bls = BLS(state = s)\n",
    "            bls.df[f'Monthly Unemployment Rate ({bls.df.Period.unique()[0]})'] = bls.df['Unemployment Rate']*0.01\n",
    "            bls.df = bls.df.drop(columns=['Unemployment Rate', 'Period'])\n",
    "            bls_df = pd.concat([bls_df, bls.df], ignore_index=True)\n",
    "            del bls\n",
    "\n",
    "#################################################\n",
    "# Define functions for curating data ############\n",
    "#################################################\n",
    "\n",
    "### economic data\n",
    "def gen_econ_data(countyDf = sdoh_county_df, tractDf = sdoh_tract_df):\n",
    "    print('Generating economic data tables...')\n",
    "    \n",
    "    econ_county = countyDf['demo_all'].loc[:, :'State'].sort_values('FIPS').reset_index(drop = True)\n",
    "    econ_tract = tractDf['demo_all'].loc[:, :'State'].sort_values('FIPS').reset_index(drop = True)\n",
    "    \n",
    "    # add insurnace\n",
    "    econ_county = econ_county.merge(countyDf['insurance'], on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.merge(tractDf['insurance'], on=['FIPS', 'Tract', 'County', 'State'], how='left')  \n",
    "    \n",
    "    # add gini_index\n",
    "    econ_county = econ_county.merge(countyDf['gini_index'], on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.merge(tractDf['gini_index'], on=['FIPS', 'Tract', 'County', 'State'], how='left')  \n",
    "    \n",
    "    # add median_household_income\n",
    "    econ_county = econ_county.merge(countyDf['income'].loc[:,:'median_income_all'],\\\n",
    "                                    on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.merge(tractDf['income'].loc[:,:'median_income_all'],\\\n",
    "                                  on=['FIPS', 'Tract', 'County', 'State'], how='left')  \n",
    "    \n",
    "    # add annual_unemployment\n",
    "    econ_county = econ_county.merge(countyDf['employment'], on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.merge(tractDf['employment'], on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    \n",
    "    # add poverty\n",
    "    econ_county = econ_county.merge(countyDf['poverty'], on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_county = econ_county.drop(columns=['below_poverty_x.5', 'below_poverty_x2'])\n",
    "    \n",
    "    econ_tract = econ_tract.merge(tractDf['poverty'], on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.drop(columns=['below_poverty_x.5', 'below_poverty_x2'])\n",
    "    \n",
    "    # rename columns\n",
    "    colnames = {'Labor Force Participation Rate': 'Annual Labor Force Participation Rate (2015-2019)',\n",
    "                'Unemployment Rate' : 'Annual Unemployment Rate (2015-2019)',\n",
    "                'health_insurance_coverage_rate': 'Insurance Coverage',\n",
    "                'Gini Index': 'Gini Coefficient',\n",
    "                'median_income_all': 'Household Income',\n",
    "                'medicaid' : 'Medicaid Enrollment',\n",
    "                'below_poverty' : 'Below Poverty'\n",
    "                }\n",
    "    \n",
    "    econ_county.rename(columns = colnames, inplace = True)\n",
    "    econ_tract.rename(columns = colnames, inplace = True)\n",
    "    \n",
    "    # calculate uninsured\n",
    "    econ_county['Uninsured'] = 1-econ_county['Insurance Coverage']\n",
    "    econ_tract['Uninsured'] = 1-econ_tract['Insurance Coverage']\n",
    "    \n",
    "    # monthly unemployment    \n",
    "    econ_county = econ_county.merge(bls_df, on='FIPS', how='left')\n",
    "    \n",
    "    return({'county': econ_county, 'tract':econ_tract})\n",
    "\n",
    "\n",
    "### housing and transportation data\n",
    "def gen_housing_transportation_data(countyDf = sdoh_county_df, tractDf = sdoh_tract_df):\n",
    "    print('Generating housing and transportation data tables...')\n",
    "    \n",
    "    # vacancy    \n",
    "    housing_county = countyDf['vacancy'].sort_values('FIPS').reset_index(drop = True)\n",
    "    housing_tract = tractDf['vacancy'].sort_values('FIPS').reset_index(drop = True)\n",
    "    \n",
    "    # transporation\n",
    "    housing_county = \\\n",
    "        housing_county.merge(countyDf['transportation'].loc[:,:'no_vehicle'], \\\n",
    "                             on=['FIPS', 'County', 'State'], how='left')\n",
    "    housing_tract = housing_tract.merge(tractDf['transportation'].loc[:,:'no_vehicle'], \\\n",
    "                                        on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    \n",
    "    # rent_to_income\n",
    "    housing_county = housing_county.merge(countyDf['rent_to_income'], \\\n",
    "                                          on=['FIPS', 'County', 'State'], how='left')\n",
    "    housing_tract = housing_tract.merge(tractDf['rent_to_income'], \\\n",
    "                                        on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    \n",
    "    housing_county.rename(columns = {'vacancy_rate': 'Vacancy Rate', 'no_vehicle': 'No Vehicle',\n",
    "                                     'rent_over_40':'Rent Burden (40% Income)'}, inplace = True)\n",
    "    housing_tract.rename(columns = {'vacancy_rate': 'Vacancy Rate', 'no_vehicle': 'No Vehicle',\n",
    "                                 'rent_over_40':'Rent Burden (40% Income)'}, inplace = True)\n",
    "    housing_county.sort_values('FIPS', inplace = True)\n",
    "    housing_tract.sort_values('FIPS', inplace = True)\n",
    "    return({'ht_county': housing_county, 'ht_tract': housing_tract})\n",
    "\n",
    "\n",
    "\n",
    "### sociodemographic data\n",
    "# create function to add race/ethnicity\n",
    "def add_race(table, sdoh_df, race):\n",
    "    table = table.sort_values('FIPS')\n",
    "    dat = sdoh_df[f'demo_{race}'].sort_values('FIPS')[['FIPS', 'total']].rename(columns={'total': f'{race}'})\n",
    "    table = table.merge(dat, on='FIPS', how='left')\n",
    "    return(table)\n",
    "\n",
    "# gather sociodemographic data\n",
    "def gen_sociodemographic_data(countyDf = sdoh_county_df, tractDf = sdoh_tract_df):\n",
    "    print('Generating sociodemographic data tables...')\n",
    "    \n",
    "    # population\n",
    "    sociodemo_county = countyDf['demo_total'].sort_values('FIPS').reset_index(drop = True)\n",
    "    sociodemo_tract = tractDf['demo_total'].sort_values('FIPS').reset_index(drop = True)\n",
    "    \n",
    "    #education\n",
    "    sociodemo_county = sociodemo_county.merge(countyDf['education'], \\\n",
    "                                              on=['FIPS', 'County', 'State'], how='left')\n",
    "    sociodemo_tract = sociodemo_tract.merge(tractDf['education'], \\\n",
    "                                            on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    \n",
    "    # race/ethnicity\n",
    "    race = ['White','Black','Hispanic','Asian','Other_Races']\n",
    "    for r in race:\n",
    "        sociodemo_county = add_race(sociodemo_county, countyDf, r)\n",
    "        sociodemo_tract = add_race(sociodemo_tract, tractDf, r)\n",
    "    \n",
    "    # % rural\n",
    "    sociodemo_county = sociodemo_county.merge(countyDf['urban_rural'], \\\n",
    "                                              on=['FIPS', 'County', 'State'], how='left')\n",
    "    sociodemo_county.sort_values('FIPS', inplace = True)\n",
    "    sociodemo_tract.sort_values('FIPS', inplace = True)\n",
    "    return({'county': sociodemo_county, 'tract': sociodemo_tract})\n",
    "\n",
    "\n",
    "\n",
    "### gather location data\n",
    "def gen_location_data():\n",
    "    print('Collecting provider and facility location data...')\n",
    "    if not ca.empty:\n",
    "        place = caSA\n",
    "        place2 = caFIPS\n",
    "    else:\n",
    "        place = stateDf.StateAbbrev\n",
    "        place2 = stateDf.StateAbbrev\n",
    "    \n",
    "    point_df = facilities()\n",
    "    \n",
    "    print('Collecting HPSA facility data...')\n",
    "    point_df.hpsa(location = place2)\n",
    "    \n",
    "    print('Collecting FQHC data...')\n",
    "    point_df.fqhc(location = place2)\n",
    "    \n",
    "    print('Collecting provider data...')\n",
    "    point_df.nppes(location = place)\n",
    "    \n",
    "    print('Collecting mammography facility data...')\n",
    "    point_df.mammography(state = place)\n",
    "    \n",
    "    print('Collecting lung cancer screening facility data...')\n",
    "    point_df.lung_cancer_screening(download_path = dl_path, location = place)\n",
    "    \n",
    "    lcs = point_df.lung_cancer_screening_df\n",
    "    nppes = point_df.nppes_df\n",
    "    mammo = point_df.mammography_df\n",
    "    hpsa = point_df.hpsa_df\n",
    "    fqhc = point_df.fqhc_df\n",
    "    point_df = pd.concat([lcs, nppes, mammo, hpsa, fqhc]).sort_values('Type')\n",
    "    \n",
    "    return(point_df)\n",
    "\n",
    "\n",
    "    \n",
    "### gather environmental data\n",
    "def gen_env_data(water_violation_start_year = 2016):\n",
    "    print('Collecting environmental data...')\n",
    "    env_county = pd.DataFrame()\n",
    "    # water violations\n",
    "    print('Collecting safe drinking water violations...')\n",
    "    for s in caSA:\n",
    "        water = water_violation(state = s, start_year = 2016) \n",
    "        env_county = pd.concat([env_county, water.df])\n",
    "    # env_county['FIPS'] = env_county.FIPS.astype(int)\n",
    "    env_county.rename(columns ={'counts': f'PWS_Violations_Since_{water_violation_start_year}' }, inplace = True)\n",
    "    env_county = env_county.merge(stateDf, on='StateAbbrev', how='left')\n",
    "    env_county = sdoh_county_df['poverty'].merge(env_county, on=['County', 'State'], how='left')\n",
    "    env_county = env_county[['FIPS', 'County', 'State', f'PWS_Violations_Since_{water_violation_start_year}']]\n",
    "    \n",
    "    # broadband speeds\n",
    "    print('Collecting broadband data...')\n",
    "    fcc_data = pd.DataFrame()\n",
    "        \n",
    "    for s in caSA:\n",
    "        FCC = fcc(state=s, download_path = dl_path) \n",
    "        fcc_data = pd.concat([fcc_data, FCC.fcc_data], ignore_index=True)\n",
    "        del FCC\n",
    "            \n",
    "    fcc_data['FIPS'] = fcc_data['BlockCode'].astype(str).str[:5]\n",
    "    fcc_data = fcc_data[fcc_data['FIPS'].isin(caFIPS)]\n",
    "    fcc_data = fcc_data.drop(columns='FIPS')\n",
    "    fcc_data = fcc_data.groupby(by = [\"BlockCode\"], as_index = False).mean()\n",
    "    fcc_data.rename(columns = {'MaxAdDown': 'avgMaxAdDown', 'MaxAdUp': 'avgMaxAdUp'}, inplace = True)\n",
    "\n",
    "    # food_desert\n",
    "    print('Collecting food desert data...')\n",
    "    food  = food_desert(state = caState)\n",
    "    env_tract = food.food_desert\n",
    "    env_tract['Census_Tract_2019'] = env_tract.FIPS.astype(str).str.zfill(11)\n",
    "    env_tract['FIPS'] = env_tract['Census_Tract_2019'].str[:5]\n",
    "    env_tract = env_tract[['FIPS', 'Census_Tract_2019','LILATracts_Vehicle']]\n",
    "    env_tract = sdoh_county_df['poverty'].iloc[:,:3].merge(env_tract, on = 'FIPS', how='left')\n",
    "    env_tract.sort_values('FIPS', inplace = True)\n",
    "    \n",
    "    print('Aggregating food desert data to county-level...')\n",
    "    food.convert_region()\n",
    "    county_food = food.food_desert\n",
    "    county_food['FIPS'] = county_food.FIPS.astype(str).str.zfill(5)\n",
    "    env_county = env_county.iloc[:,:4].merge(county_food, on='FIPS', how='left')\n",
    "    env_county.sort_values('FIPS', inplace = True)\n",
    "    \n",
    "    return({'environment_county': env_county, 'environment_tract': env_tract,\n",
    "                'broadband_speeds': fcc_data})\n",
    "\n",
    "### gather cancer data\n",
    "def gen_cancer_data():\n",
    "    print('Collecting cancer incidence and mortality data...')\n",
    "    inc_data = pd.DataFrame()\n",
    "    mor_data = pd.DataFrame()\n",
    "    \n",
    "    for s in caStateFIPS:\n",
    "        cnr = scp_cancer_data(state = s)\n",
    "        inc_data = pd.concat([inc_data, cnr.incidence], ignore_index=True)\n",
    "        mor_data = pd.concat([mor_data, cnr.mortality], ignore_index=True)\n",
    "        del cnr\n",
    "    \n",
    "    inc_data = inc_data.merge(stateDf, on='FIPS2', how='left')\n",
    "    caInc = inc_data[['FIPS', 'County', 'State', 'Type', 'Site', 'AAR', 'AAC']]\n",
    "    caInc = caInc[caInc['FIPS'].isin(caFIPS)]\n",
    "    \n",
    "    mor_data = mor_data.merge(stateDf, on='FIPS2', how='left')\n",
    "    caMor = mor_data[['FIPS', 'County', 'State', 'Type', 'Site', 'AAR', 'AAC']]\n",
    "    caMor = caMor[caMor['FIPS'].isin(caFIPS)]\n",
    "    \n",
    "    return({'cancer_incidence': caInc, 'cancer_mortality': caMor})\n",
    "    \n",
    "### gather CDC Places data\n",
    "def gen_places_data():\n",
    "    print('Collecting risk factor and screening data...')\n",
    "    places_county_data = pd.DataFrame()\n",
    "    places_tract_data = pd.DataFrame()\n",
    "    \n",
    "    for s in caSA:\n",
    "        places = places_data(state = s)\n",
    "        places_county_data = pd.concat([places_county_data, places.county_est], ignore_index=True)\n",
    "        places_tract_data = pd.concat([places_tract_data, places.tract_est], ignore_index=True)\n",
    "        del places\n",
    "    \n",
    "    placesCounty = places_county_data[places_county_data['FIPS'].isin(caFIPS)]\n",
    "    placesCounty_l = pd.melt(placesCounty, id_vars=['FIPS', 'County', 'State'], \n",
    "                              var_name='measure', value_name='value')\n",
    "    placesCounty_l['value'] = pd.to_numeric(placesCounty_l['value'])/100\n",
    "    \n",
    "    placesTract = places_tract_data[places_tract_data['FIPS5'].isin(caFIPS)]\n",
    "    placesTract = placesTract.drop(columns=['FIPS5'])\n",
    "    placesTract_l = pd.melt(placesTract, id_vars=['FIPS', 'County', 'State'],\n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    placesTract_l['value'] = pd.to_numeric(placesTract_l['value'])/100\n",
    "    \n",
    "    return({'rfs_county': placesCounty_l, 'rfs_tract': placesTract_l})\n",
    "    \n",
    "#################################################\n",
    "# Compile Data and Write to File ################\n",
    "#################################################\n",
    "\n",
    "### compile data\n",
    "def comp_data():\n",
    "    rfs = gen_places_data()\n",
    "    rfs_county_l, rfs_tract_l = rfs['rfs_county'], rfs['rfs_tract']\n",
    "    rfs_county = pd.pivot(rfs_county_l, index=['FIPS', 'County', 'State'], columns='measure', values='value')\n",
    "    rfs_tract = pd.pivot(rfs_tract_l, index=['FIPS', 'County', 'State'], columns='measure', values='value')\n",
    "    cancer = gen_cancer_data()\n",
    "    cancer_inc_l, cancer_mor_l = cancer['cancer_incidence'], cancer['cancer_mortality']\n",
    "    cancer_inc = pd.pivot(cancer_inc_l, index=['FIPS', 'County', 'State', 'Type'], columns='Site', values='AAR')\n",
    "    cancer_mor = pd.pivot(cancer_mor_l, index=['FIPS', 'County', 'State', 'Type'], columns='Site', values='AAR')\n",
    "    econ = gen_econ_data()\n",
    "    econ_county, econ_tract = econ['county'], econ['tract']\n",
    "    econ_county_l = pd.melt(econ_county, id_vars = ['FIPS', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    econ_tract_l = pd.melt(econ_tract, id_vars = ['FIPS', 'Tract', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    housing_transportation = gen_housing_transportation_data()\n",
    "    ht_county, ht_tract = housing_transportation['ht_county'], housing_transportation['ht_tract']\n",
    "    ht_county_l = pd.melt(ht_county, id_vars = ['FIPS', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    ht_tract_l = pd.melt(ht_tract, id_vars = ['FIPS', 'Tract', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    sociodemo = gen_sociodemographic_data()\n",
    "    sociodemo_county, sociodemo_tract = sociodemo['county'], sociodemo['tract']\n",
    "    sd_county_l = pd.melt(sociodemo_county, id_vars = ['FIPS', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    sd_tract_l = pd.melt(sociodemo_tract, id_vars = ['FIPS', 'Tract', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    env = gen_env_data()\n",
    "    env_county, env_tract, broadband_data = env['environment_county'], env['environment_tract'], env['broadband_speeds']\n",
    "    env_county_l = pd.melt(env_county, id_vars = ['FIPS', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    env_tract_l = pd.melt(env_tract, id_vars = ['FIPS', 'County', 'State', 'Census_Tract_2019'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    point_df = gen_location_data()\n",
    "    \n",
    "    return({'rf_and_screening_county': rfs_county, 'rf_and_screening_county_long': rfs_county_l,\n",
    "            'rf_and_screening_tract': rfs_tract, 'rf_and_screening_tract_long': rfs_tract_l,\n",
    "            'cancer_incidence': cancer_inc, 'cancer_incidence_long': cancer_inc_l,\n",
    "            'cancer_mortality': cancer_mor, 'cancer_mortality_long': cancer_mor_l,\n",
    "            'economy_county': econ_county, 'economy_county_long': econ_county_l,\n",
    "            'economy_tract': econ_tract, 'economy_tract_long': econ_tract_l,\n",
    "            'ht_county': ht_county, 'ht_county_long': ht_county_l, \n",
    "            'ht_tract': ht_tract, 'ht_tract_long': ht_tract_l, \n",
    "            'sociodemographics_county': sociodemo_county, 'sd_county_long': sd_county_l,\n",
    "            'sociodemographics_tract': sociodemo_tract, 'sd_tract_long': sd_tract_l,\n",
    "            'environment_county': env_county, 'environment_county_long': env_county_l,\n",
    "            'environment_tract': env_tract, 'environment_tract_long': env_tract_l,\n",
    "            'broadband_speeds': broadband_data, 'facilities_and_providers': point_df})\n",
    "\n",
    "### write data to Excel\n",
    "def save_as_xlsx():\n",
    "    from pandas import ExcelWriter\n",
    "    from datetime import datetime as dt\n",
    "    \n",
    "    ca_dir = ca_name.replace(\" \", \"_\") + \"_catchment_data\"\n",
    "    path2 = os.path.join(os.getcwd(), ca_dir)\n",
    "    \n",
    "    if os.path.exists(path2) == False:\n",
    "        os.makedirs(path2)\n",
    "        \n",
    "    save_name = ca_name.replace(\" \", \"_\") + '_catchment_data_' + dt.today().strftime('%m-%d-%Y') + '.xlsx'\n",
    "    save_name2 = ca_name.replace(\" \", \"_\") + '_catchment_data_long_' + dt.today().strftime('%m-%d-%Y') + '.xlsx'\n",
    "    full_path = os.path.join(os.getcwd(), ca_dir, save_name)\n",
    "    full_path2 = os.path.join(os.getcwd(), ca_dir, save_name2)\n",
    "\n",
    "    with ExcelWriter(full_path, mode = 'w') as writer:\n",
    "        print('Writing data to file...')\n",
    "        pd.read_csv('CIFTools_Documentation.csv', \n",
    "                    header = None, encoding = \"ISO-8859-1\").to_excel(writer, header = None, \n",
    "                                                                     sheet_name = 'Variables and Sources', index = False)\n",
    "        cdata['cancer_incidence'].to_excel(writer, sheet_name = 'Cancer Incidence', index = True)\n",
    "        cdata['cancer_mortality'].to_excel(writer, sheet_name = 'Cancer Mortality', index = True)\n",
    "        cdata['economy_county'].to_excel(writer, sheet_name = 'Economy (County)', index = False)\n",
    "        cdata['economy_tract'].to_excel(writer, sheet_name = 'Economy (Tract)', index = False)\n",
    "        cdata['environment_county'].to_excel(writer, sheet_name = 'Environment (County)', index = False)\n",
    "        cdata['environment_tract'].to_excel(writer, sheet_name = 'Environment (Tract)', index = False)\n",
    "        #cdata['broadband_speeds'].to_excel(writer, sheet_name = 'Broadband Speeds', index = False) #can be too long in some areas\n",
    "        cdata['ht_county'].to_excel(writer, sheet_name = 'H and T (County)', index = False)\n",
    "        cdata['ht_tract'].to_excel(writer, sheet_name= 'H and T (Tract)', index = False)\n",
    "        cdata['rf_and_screening_county'].to_excel(writer, sheet_name= 'RF and Screening (County)', index=True)\n",
    "        cdata['rf_and_screening_tract'].to_excel(writer, sheet_name= 'RF and Screening (Tract)', index=True)\n",
    "        cdata['sociodemographics_county'].to_excel(writer, sheet_name = 'Sociodemographic (County)', index = False)\n",
    "        cdata['sociodemographics_tract'].to_excel(writer, sheet_name = 'Sociodemographic (Tract)', index = False)\n",
    "        cdata['facilities_and_providers'].to_excel(writer, sheet_name = 'Facilities', index = False)\n",
    "        \n",
    "    with ExcelWriter(full_path2, mode = 'w') as writer:\n",
    "        print('Writing data to file...')\n",
    "        pd.read_csv('CIFTools_Documentation.csv', \n",
    "                    header = None, encoding = \"ISO-8859-1\").to_excel(writer, header = None, \n",
    "                                                                     sheet_name = 'Variables and Sources', index = False)\n",
    "        cdata['cancer_incidence_long'].to_excel(writer, sheet_name = 'Cancer Incidence', index = True)\n",
    "        cdata['cancer_mortality_long'].to_excel(writer, sheet_name = 'Cancer Mortality', index = True)\n",
    "        cdata['economy_county_long'].to_excel(writer, sheet_name = 'Economy (County)', index = False)\n",
    "        cdata['economy_tract_long'].to_excel(writer, sheet_name = 'Economy (Tract)', index = False)\n",
    "        cdata['environment_county_long'].to_excel(writer, sheet_name = 'Environment (County)', index = False)\n",
    "        cdata['environment_tract_long'].to_excel(writer, sheet_name = 'Environment (Tract)', index = False)\n",
    "        #cdata['broadband_speeds'].to_excel(writer, sheet_name = 'Broadband Speeds', index = False) # can be too long in some areas\n",
    "        cdata['ht_county_long'].to_excel(writer, sheet_name = 'H and T (County)', index = False)\n",
    "        cdata['ht_tract_long'].to_excel(writer, sheet_name= 'H and T (Tract)', index = False)\n",
    "        cdata['rf_and_screening_county_long'].to_excel(writer, sheet_name= 'RF and Screening (County)', \n",
    "                                                        index=True)\n",
    "        cdata['rf_and_screening_tract_long'].to_excel(writer, sheet_name= 'RF and Screening (Tract)', \n",
    "                                                      index=True)\n",
    "        cdata['sd_county_long'].to_excel(writer, sheet_name = 'Sociodemographic (County)', index = False)\n",
    "        cdata['sd_tract_long'].to_excel(writer, sheet_name = 'Sociodemographic (Tract)', index = False)\n",
    "        cdata['facilities_and_providers'].to_excel(writer, sheet_name = 'Facilities', index = False)\n",
    "    \n",
    "    print(save_name + ' created')\n",
    "    \n",
    "    return\n",
    "\n",
    "### write data to CSVs\n",
    "def save_as_csvs():\n",
    "    from datetime import datetime as dt\n",
    "    today = dt.today().strftime('%m-%d-%Y')\n",
    "    ca_dir = ca_name.replace(\" \", \"_\") + \"_catchment_data\"\n",
    "    path2 = os.path.join(os.getcwd(), ca_dir)\n",
    "    \n",
    "    if os.path.exists(path2) == False:\n",
    "        os.makedirs(path2)\n",
    "        \n",
    "    os.chdir(path2)\n",
    "    \n",
    "    cdata['cancer_incidence'].to_csv(ca_name + '_cancer_incidence_county_' + today + '.csv', encoding='utf-8', index=True)\n",
    "    cdata['cancer_mortality'].to_csv(ca_name + '_cancer_mortality_county_' + today + '.csv', encoding='utf-8', index=True)\n",
    "    cdata['cancer_incidence_long'].to_csv(ca_name + '_cancer_incidence_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['cancer_mortality_long'].to_csv(ca_name + '_cancer_mortality_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['economy_county'].to_csv(ca_name + '_economy_county_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['economy_county_long'].to_csv(ca_name + '_economy_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['economy_tract'].to_csv(ca_name + '_economy_tract_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['economy_tract_long'].to_csv(ca_name + '_economy_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['environment_county'].to_csv(ca_name + '_environment_county_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['environment_county_long'].to_csv(ca_name + '_environment_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['environment_tract'].to_csv(ca_name + '_environment_tract_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['environment_tract_long'].to_csv(ca_name + '_environment_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['ht_county'].to_csv(ca_name + '_housing_trans_county_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['ht_county_long'].to_csv(ca_name + '_housing_trans_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['ht_tract'].to_csv(ca_name + '_housing_trans_tract_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['ht_tract_long'].to_csv(ca_name + '_housing_trans_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['rf_and_screening_county'].to_csv(ca_name + '_rf_and_screening_county_' + today + '.csv', encoding='utf-8', index=True)\n",
    "    cdata['rf_and_screening_tract'].to_csv(ca_name + '_rf_and_screening_tract_' + today + '.csv', encoding='utf-8', index=True)\n",
    "    cdata['rf_and_screening_county_long'].to_csv(ca_name + '_rf_and_screening_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['rf_and_screening_tract_long'].to_csv(ca_name + '_rf_and_screening_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['sociodemographics_county'].to_csv(ca_name + '_sociodemographics_county_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['sd_county_long'].to_csv(ca_name + '_sociodemographics_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['sociodemographics_tract'].to_csv(ca_name + '_sociodemographics_tract_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['sd_tract_long'].to_csv(ca_name + '_sociodemographics_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['broadband_speeds'].to_csv(ca_name + '_broadband_speeds_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['facilities_and_providers'].to_csv(ca_name + '_facilities_and_providers_' + today + '.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    print('Success! CSVs created')\n",
    "\n",
    "    return\n",
    "\n",
    "# run compile and write functions\n",
    "if __name__ == '__main__':\n",
    "    cdata = comp_data()  \n",
    "    #save_as_xlsx()\n",
    "    save_as_csvs()\n",
    "    os.chdir('/content')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F33C-G6qoMri"
   },
   "source": [
    "Finally, zip the output and download it to your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2eYz3xaoTay"
   },
   "outputs": [],
   "source": [
    "ca_dir = ca_name.replace(\" \", \"_\") + \"_catchment_data\"\n",
    "\n",
    "!zip -r /content/{ca_dir}.zip /content/{ca_dir}\n",
    "\n",
    "from google.colab import files\n",
    "files.download(f'/content/{ca_dir}.zip')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
